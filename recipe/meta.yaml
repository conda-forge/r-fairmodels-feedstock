{% set version = '1.2.1' %}
{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-fairmodels
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/fairmodels_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/fairmodels/fairmodels_{{ version }}.tar.gz
  sha256: 97c39e00fe05402bc65b03d05f14698ed8101266e837f3534dac09d8cb17b373

build:
  noarch: generic
  number: 0
  rpaths:
    - lib/R/lib/
    - lib/

requirements:
  build:
    - cross-r-base {{ r_base }}    # [build_platform != target_platform]
  host:
    - r-base
    - r-dalex
    - r-ggplot2
    - r-patchwork
    - r-scales
  run:
    - r-base
    - r-dalex
    - r-ggplot2
    - r-patchwork
    - r-scales

test:
  commands:
    - $R -e "library('fairmodels')"           # [not win]

about:
  home: https://fairmodels.drwhy.ai/
  license: GPL-3.0-only
  summary: "Measure fairness metrics in one place for many models. Check how big is model's bias
    towards different races, sex, nationalities etc. Use measures such as Statistical
    Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize
    the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various
    pre-processing and post-processing bias mitigation algorithms implemented. Package
    also supports calculating fairness metrics for regression models. Find more details
    in (Wi\u015Bniewski, Biecek (2021)) <arXiv:2104.00507>."
  license_family: GPL3
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/GPL-3'

extra:
  recipe-maintainers:
    - conda-forge/r
    - dillonroach

# Package: fairmodels
# Type: Package
# Title: Flexible Tool for Bias Detection, Visualization, and Mitigation
# Version: 1.2.1
# Authors@R: c(person("Jakub", "Wisniewski", role = c("aut", "cre"), email = "jakwisn@gmail.com"), person("Przemysaw", "Biecek", role = c("aut"), comment = c(ORCID = "0000-0001-8423-1823")))
# Description: Measure fairness metrics in one place for many models. Check how big is model's bias towards different races, sex, nationalities etc. Use measures such as Statistical Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various pre-processing and post-processing bias mitigation algorithms implemented. Package also supports calculating fairness metrics for regression models. Find more details in (Wisniewski, Biecek (2021)) <arXiv:2104.00507>.
# License: GPL-3
# Encoding: UTF-8
# LazyData: true
# Depends: R (>= 3.5)
# Imports: DALEX, ggplot2, scales, stats, patchwork,
# Suggests: ranger, gbm, knitr, rmarkdown, covr, testthat, spelling, ggdendro, ggrepel,
# RoxygenNote: 7.1.1.9001
# VignetteBuilder: knitr
# URL: https://fairmodels.drwhy.ai/
# BugReports: https://github.com/ModelOriented/fairmodels/issues
# Language: en-US
# NeedsCompilation: no
# Packaged: 2022-08-23 19:31:51 UTC; jakwi
# Author: Jakub Wisniewski [aut, cre], Przemysaw Biecek [aut] (<https://orcid.org/0000-0001-8423-1823>)
# Maintainer: Jakub Wisniewski <jakwisn@gmail.com>
# Repository: CRAN
# Date/Publication: 2022-08-23 19:50:06 UTC
